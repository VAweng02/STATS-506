---
title: "STATS 506 - Homework 6"
author: "Vincent Weng"
format:
  html:
    embed-resources: true
---

<h3>Stratified Bootstrapping</h3>

Part (A) - Calculate the average RF for each team in the Fielding table. Then, since we donâ€™t have a closed form for the standard deviation of this statistic, carry out a stratified bootstrap by team to estimate it. Do this out three ways:

1. Without any parallel processing
2. Using parallel processing with the parallel package.
3. Using futures with the future package.


Loading in data
```{r}
library(DBI)
library(RSQLite)
library(tidyverse)

# Connect to Lahman db
con <- dbConnect(RSQLite::SQLite(), "lahman_1871-2022.sqlite")

fielding <- dbReadTable(con, "Fielding")

fielding <- fielding %>%
  mutate(RF = 3 * (PO + A) / InnOuts)  # Compute RF

fielding <- fielding %>%
  filter(InnOuts > 0)  # Remove rows where InnOuts are zero

fielding <- fielding %>%
  mutate(RF = ifelse(is.nan(RF) | is.infinite(RF), NA, RF))

# Check if any invalid values remain
sum(is.infinite(fielding$RF))  # Should return 0
sum(is.nan(fielding$RF))      # Should return 0
sum(is.na(fielding$RF))       # Count rows where RF is NA

# Compute RF for each player
fielding$RF <- 3 * (fielding$PO + fielding$A) / fielding$InnOuts

# Average RF by team
team_rf <- fielding %>%
  group_by(teamID) %>%
  summarize(avg_RF = mean(RF, na.rm = TRUE))

dbDisconnect(con)
```




Without any parallel processing
```{r}
##' @title Stratified Bootstrap function
##' @param data and number of bootstrap samples
##' @return 1000 bootstrap samples
stratified_bootstrap <- function(data, n_boot = 1000) {
  replicate(n_boot, {
    data %>%
      group_by(teamID) %>%
      sample_n(size = n(), replace = TRUE) %>%
      summarise(avg_RF = mean(RF, na.rm = TRUE))
  }, simplify = FALSE) %>%
    bind_rows(.id = "replicate")
}

set.seed(123) # Set seed
time_no_parallel <- system.time({
  boot_no_parallel <- stratified_bootstrap(fielding, n_boot = 1000)
})

# Computing estimated RF and SE for teams with 10 highest RF
top_10_teams1 <- boot_no_parallel %>%
                  group_by(teamID) %>% # Group by teamID
                  summarise(
                    mean_RF = mean(avg_RF, na.rm = TRUE), # Calculate mean RF
                    std_error = sd(avg_RF, na.rm = TRUE) # Calculate SE
                  ) %>%
                  arrange(desc(mean_RF)) %>% # Sort by mean RF desc
                  slice(1:10) 

print(top_10_teams1)
```





Using parallel processing with the parallel package
```{r}
library(parallel)

# Define number of cores
time_parallel <- system.time({
  cl <- makeCluster(detectCores() - 1)
  clusterExport(cl, varlist = c("fielding", "stratified_bootstrap"))
  clusterEvalQ(cl, library(dplyr))
  
  # Perform stratified bootstrap
  set.seed(123)
  boot_parallel <- parLapply(cl, 1:1000, function(i) {
    fielding %>%
      group_by(teamID) %>%
      sample_n(size = n(), replace = TRUE) %>%
      summarise(avg_RF = mean(RF, na.rm = TRUE))
  })
  stopCluster(cl)
  
  # Combine results
  boot_parallel <- bind_rows(boot_parallel, .id = "replicate")
})
  
# Computing estimated RF and SE for teams with 10 highest RF
top_10_teams2 <- boot_parallel %>%
                  group_by(teamID) %>% # Group by teamID
                  summarise(
                    mean_RF = mean(avg_RF, na.rm = TRUE), # Calculate mean RF
                    std_error = sd(avg_RF, na.rm = TRUE) # Calculate SE
                  ) %>%
                  arrange(desc(mean_RF)) %>% # Sort by mean RF desc
                  slice(1:10) 

print(top_10_teams2)
```


Using futures with the future package
```{r}
library(future)
library(furrr)

plan(multisession, workers = detectCores() - 1)

# Using future package
suppressWarnings({
  # Code block where warnings are suppressed
  time_futures <- system.time({
    boot_futures <- future_map_dfr(1:1000, ~ {
      fielding %>%
        group_by(teamID) %>%
        sample_n(size = n(), replace = TRUE) %>%
        summarise(avg_RF = mean(RF, na.rm = TRUE))
    }, future.seed = TRUE)
  })
})

# Computing estimated RF and SE for teams with 10 highest RF
top_10_teams3 <- boot_futures %>%
                  group_by(teamID) %>% # Group by teamID
                  summarise(
                    mean_RF = mean(avg_RF, na.rm = TRUE), # Calculate mean RF
                    std_error = sd(avg_RF, na.rm = TRUE) # Calculate SE
                  ) %>%
                  arrange(desc(mean_RF)) %>% # Sort by mean RF desc
                  slice(1:10) 

print(top_10_teams3)
```





Part (B) - Generate a table showing the estimated RF and associated standard errors from the three approaches.
```{r}
library(dplyr)
library(knitr)

# Add a column to each dataset to identify the method
top_10_teams1 <- top_10_teams1 %>% mutate(Method = "No Parallel")
top_10_teams2 <- top_10_teams2 %>% mutate(Method = "Parallel")
top_10_teams3 <- top_10_teams3 %>% mutate(Method = "Futures")

# Combine all results into one table (30 rows)
combined_results <- bind_rows(top_10_teams1, top_10_teams2, top_10_teams3)

# Print the combined table
kable(combined_results, caption = "Estimated RF and Standard Errors from Three Approaches")
```



Part (C) - Report and discuss the performance difference between the versions.
```{r}
# Combine execution times into a table
time_table <- data.frame(
  Method = c("No Parallel", "Parallel", "Futures"),
  Execution_Time = c(time_no_parallel[3], time_parallel[3], time_futures[3])
)
print(time_table)
```
The performance comparison shows that parallel processing significantly improves execution speed. The No Parallel method took the longest at 22.52 seconds, while the Parallel and Futures methods reduced execution time to 4.913 seconds and 5.342 seconds, respectively. Parallel offers the best performance, but Futures provides a more user-friendly interface with comparable efficiency. Both Parallel and Futures are far more suitable than No Parallel for computationally intensive tasks like bootstrapping.