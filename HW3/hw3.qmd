---
title: "STATS 506 - Homework 3"
author: "Vincent Weng"
format:
  html:
    embed-resources: true
---

<h3>Problem 1 - Vision</h3>

Part (A) - Download the file VIX_D from this location, and determine how to read it into R. Then download the file DEMO_D from this location. Note that each page contains a link to a documentation file for that data set. Merge the two files to create a single data.frame, using the SEQN variable for merging. Keep only records which matched. Print out your total sample size, showing that it is now 6,980.
```{r}
library(haven)

vix_d <- read_xpt("/Users/vincentweng/Documents/STATS-506/HW3/VIX_D.XPT")
demo_d <- read_xpt("/Users/vincentweng/Documents/STATS-506/HW3/DEMO_D.XPT")

vision <- merge(vix_d, demo_d, by = "SEQN", all = FALSE)

nrow(vision)
```
The total sample size is now 6,980, as shown above.


Part (B) - Without fitting any models, estimate the proportion of respondents within each 10-year age bracket (e.g. 0-9, 10-19, 20-29, etc) who wear glasses/contact lenses for distance vision. Produce a nice table with the results.
```{r}
library(knitr)

vision$glasses <- ifelse(vision$VIQ220 == 9, NA, vision$VIQ220 - 1)
vision$age <- vision$RIDAGEYR
vision$agecat <- floor(vision$age / 10)

prop <- tapply(vision$glasses, vision$agecat, mean, na.rm = TRUE) * 100

prop_df <- data.frame(AgeBracket = c("10-19", "20-29", "30-39", "40-49", 
                                     "50-59", "60-69", "70-79", "80-89"),
                                      Proportion = round(prop, 1))
prop_df
```



Part(C) - Fit three logistic regression models predicting whether a respondent wears glasses/contact lenses for distance vision. Predictors:

1. age
2. age, race, gender
3. age, race, gender, Poverty Income ratio

Produce a table presenting the estimated odds ratios for the coefficients in each model, along with the sample size for the model, the pseudo-$R^2$, and AIC values.
```{r}
vision$age <- vision$RIDAGEYR
vision$gender <- vision$RIAGENDR
vision$race <- vision$RIDRETH1
vision$pov_inc_ratio <- vision$INDFMPIR

# model 1: age as predictor
model1 <- glm(glasses ~ age, data = vision, family = binomial)

# model 2: age, race, gender as predictors
model2 <- glm(glasses ~ age + race + gender, data = vision, family = binomial)

# model 3: age, race, gender, and Poverty Income ratio as predictors
model3 <- glm(glasses ~ age + race + gender + pov_inc_ratio, data = vision, family = binomial)

summary(model1)
summary(model2)
summary(model3)
```




Part(D) - From the third model from the previous part, test whether the odds of men and women being wears of glasess/contact lenses for distance vision differs. Test whether the proportion of wearers of glasses/contact lenses for distance vision differs between men and women. Include the results of the each test and their interpretation.
```{r}

```





<h3>Problem 2 - Sakila</h3>

```{r}
library(DBI)
library(RSQLite)

sakila <- dbConnect(RSQLite::SQLite(), "sakila_master.db")
```

Part(A) - What is the oldest movie (earliest release year) in the database? Answer this with a single SQL query.
```{r}
tables <- dbListTables(sakila)
print(tables)

columns <- dbListFields(sakila, "film")
print(columns)

dbGetQuery(sakila, "
  SELECT title, release_year
  FROM film
  ORDER BY release_year DESC
  LIMIT 1
")
```


Part(B) - What genre of movie is the least common in the data, and how many movies are of this genre?
```{r}
tables <- dbListTables(sakila)
print(tables)

columns <- dbListFields(sakila, "category")
print(columns)

columns <- dbListFields(sakila, "film_category")
print(columns)

dbGetQuery(sakila, "
  SELECT c.name, COUNT(c.category_id)
  FROM category AS c
  JOIN film_category AS fc ON c.category_id = fc.category_id
  GROUP BY c.category_id
  ORDER by COUNT(c.category_id) DESC
  LIMIT 1
")
```
The lease common genrie in the data is "Sports" and there are 74 movies in this genre.



Part(C) - Identify which country or countries have exactly 13 customers.
```{r}
columns <- dbListFields(sakila, "customer")
print(columns)

columns <- dbListFields(sakila, "city")
print(columns)

columns <- dbListFields(sakila, "address")
print(columns)

columns <- dbListFields(sakila, "country")
print(columns)

dbGetQuery(sakila, "
  SELECT co.country, count(co.country)
  FROM country AS co
  JOIN city AS ci ON co.country_id = ci.country_id
  JOIN address AS ad ON ci.city_id = ad.city_id
  JOIN customer as cu ON ad.address_id = cu.address_id
  GROUP BY co.country
  HAVING count(co.country) == 13
")
```
Argentina and Nigeria have exactly 13 customers.





<h3>Problem 3 - US Records</h3>

Part(A) - What proportion of email addresses are hosted at a domain with TLD “.com”? (in the email, “angrycat@freemail.org”, “freemail.org” is the domain, and “.org” is the TLD (top-level domain).)
```{r}
us_records <- read.csv("us-500.csv")
count <- sum(grepl("\\.com$", us_records$email))
print(count/nrow(us_records))
```


Part(B) - What proportion of email addresses have at least one non alphanumeric character in them? (Excluding the required “@” and “.” found in every email address.)
```{r}
# extract usernames and domains using regular expressions
usernames <- sub("@.*", "", us_records$email)   # remove everything after '@' to get usernames
domains <- sub(".*@", "", us_records$email)     # remove everything before '@' to get domains
domains <- sub("\\.[a-z]{2,3}$", "", domains)   # remove the TLD (e.g., .com, .org)

# check non-alphanumeric chars in usernames and domains
username_non_alphanumeric <- grepl("[^a-zA-Z0-9]", usernames)
domain_non_alphanumeric <- grepl("[^a-zA-Z0-9]", domains)

# calculate proportion of emails with non-alphanumeric characters
non_alphanumeric_proportion <- mean(username_non_alphanumeric | domain_non_alphanumeric)

print(non_alphanumeric_proportion)
```


Part(C) - What are the top 5 most common area codes amongst all phone numbers? (The area code is the first three digits of a standard 10-digit telephone number.)
```{r}
phone_numbers <- c(us_records$phone1, us_records$phone2)
area_codes <- substr(phone_numbers, 1, 3)
area_code_counts <- table(area_codes)
top_five <- sort(area_code_counts, decreasing = TRUE)[1:5]
print(top_five)
```
The top 5 most common area codes are "973", "212", "215", "410", and "201".




Part(D) - Produce a histogram of the log of the apartment numbers for all addresses. (You may assume any number at the end of the an address is an apartment number.)
```{r}
apt <- us_records$address[grepl("[0-9]+$", us_records$address)]
nums <- sapply(strsplit(apt, " "), function(x) x[length(x)])
nums <- as.numeric(gsub("#", "", nums))
hist(log(nums))
```



Part(E) - Benford’s law is an observation about the distribution of the leading digit of real numerical data. Examine whether the apartment numbers appear to follow Benford’s law. Do you think the apartment numbers would pass as real data?
```{r}
leading_digit_counts <- table(substr(nums, 1, 1))

# normalize the counts to get observed frequencies
observed_freq <- leading_digit_counts / sum(leading_digit_counts)

# calculate expected frequencies based on Benford's Law
benford_probs <- log10((1:9) + 1) - log10(1:9)
benford_freq <- benford_probs / sum(benford_probs)

# create a data frame for comparison
comparison_df <- data.frame(
  Digit = 1:9,
  Observed = as.numeric(observed_freq[1:9]),
  Expected = benford_freq
)

print(comparison_df)
```

From the above results, the observed distribution does not closely follow Benford's Law

